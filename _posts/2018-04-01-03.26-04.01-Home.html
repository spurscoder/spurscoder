<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>&quot;03.26到04.01.home&quot;</title><link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}#write, body { height: auto; }
#write, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write ol, #write p, #write ul { position: relative; }
#write, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write, pre { white-space: pre-wrap; }
.CodeMirror, .md-fences, table { text-align: left; }
.md-reset, a:active, a:hover { outline: 0px; }
.md-reset, .md-toc-item a { text-decoration: none; }
.MathJax_SVG, .md-reset { float: none; direction: ltr; }
:root { --bg-color: #ffffff; --text-color: #333333; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857143; overflow-x: hidden; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit inherit; background-repeat: inherit inherit; }
.in-text-selection, ::selection { background-color: rgb(181, 214, 252); text-shadow: none; background-position: initial initial; background-repeat: initial initial; }
#write { margin: 0px auto; word-break: normal; word-wrap: break-word; padding-bottom: 70px; overflow-x: visible; }
.first-line-indent #write p .md-line { text-indent: 0px; }
.first-line-indent #write li, .first-line-indent #write p, .first-line-indent #write p .md-line:first-child { text-indent: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) { 
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write > blockquote:first-child, #write > div:first-child, #write > ol:first-child, #write > p:first-child, #write > pre:first-child, #write > table:first-child, #write > ul:first-child { margin-top: 30px; }
#write li > table:first-child { margin-top: -20px; }
img { max-width: 100%; vertical-align: middle; }
button, input, select, textarea { color: inherit; font-family: inherit; font-size: inherit; font-style: inherit; font-variant-caps: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
p { -webkit-margin-before: 1rem; -webkit-margin-after: 1rem; -webkit-margin-start: 0px; -webkit-margin-end: 0px; }
.mathjax-block { margin-top: 0px; margin-bottom: 0px; -webkit-margin-before: 0px; -webkit-margin-after: 0px; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.701961); color: rgb(85, 85, 85); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
#write > figure:first-child { margin-top: 16px; }
figure { overflow-x: auto; margin: -8px 0px 0px -8px; max-width: calc(100% + 16px); padding: 8px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; }
.CodeMirror-line, .md-fences { break-inside: avoid; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right-width: 0px; background-color: inherit; margin-right: 4px; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
.md-fences { font-size: 0.9rem; display: block; overflow: visible; white-space: pre; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; position: relative !important; background-position: inherit inherit; background-repeat: inherit inherit; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
.md-fences .CodeMirror.CodeMirror-wrap { top: -1.6em; margin-bottom: -1.6em; }
.md-fences.mock-cm { white-space: pre-wrap; }
.show-fences-line-number .md-fences { padding-left: 0px; }
.show-fences-line-number .md-fences.mock-cm { padding-left: 40px; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; vertical-align: top; text-shadow: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; background-position: 0px 0px; background-repeat: initial initial; }
.md-toc-inner, a img, img a { cursor: pointer; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: nowrap; }
@media print { 
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid-page; break-before: avoid-page; }
  #write { margin-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  h1, h2, h3, h4, h5, h6 { break-after: avoid-page; orphans: 2; }
  p { orphans: 4; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid-page; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0px; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background-color: rgb(204, 204, 204); display: block; overflow-x: hidden; background-position: initial initial; background-repeat: initial initial; }
p > img:only-child { display: block; margin: auto; }
.md-line > .md-image:only-child, p > .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
.mathjax-block:not(:empty)::after, .md-toc-content::after, .md-toc::after { display: none; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.mathjax-block { white-space: pre; overflow: hidden; width: 100%; }
p + .mathjax-block { margin-top: -1.143rem; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-top-left-radius: 10px; border-top-right-radius: 10px; border-bottom-right-radius: 10px; border-bottom-left-radius: 10px; }
.MathJax_SVG, .mathjax-block .MathJax_SVG_Display { text-indent: 0px; max-width: none; max-height: none; min-height: 0px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) { 
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, tt { font-family: var(--monospace); }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; }
a.md-print-anchor { border: none !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; text-shadow: initial !important; background-position: 0px 0px !important; background-repeat: initial initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.mathjax-block .MathJax_SVG_Display { text-align: center; margin: 1em 0px; position: relative; min-width: 100%; width: auto; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: monospace; }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; min-width: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg, [lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom-width: 0px; }


.CodeMirror, .CodeMirror-sizer { position: relative; }
.CodeMirror.cm-s-inner { background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit inherit; background-repeat: inherit inherit; }
.fences-no-line-wrapping .md-fences .CodeMirror { margin-top: -30px; }
.CodeMirror-scroll { overflow-y: hidden; overflow-x: auto; }
.CodeMirror-lines { padding: 4px 0px; }
.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler { background-color: rgb(255, 255, 255); }
.CodeMirror-scroll, .cm-s-inner .CodeMirror-activeline-background { background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit inherit; background-repeat: inherit inherit; }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: rgb(0, 0, 0); }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-property { color: rgb(0, 0, 0); }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta, .cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: rgb(0, 0, 255); }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: 700; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error, .cm-invalidchar { color: red; }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.CodeMirror { height: auto; overflow: hidden; }
.CodeMirror-scroll { margin-bottom: -30px; padding-bottom: 30px; height: 100%; outline: 0px; position: relative; box-sizing: content-box; }
.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar { position: absolute; z-index: 6; display: none; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow-x: hidden; overflow-y: scroll; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow-y: hidden; overflow-x: scroll; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; white-space: nowrap; position: absolute; left: 0px; top: 0px; padding-bottom: 30px; z-index: 3; background-position: inherit inherit; background-repeat: inherit inherit; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-wrapper { position: absolute; z-index: 4; border: none !important; background-position: 0px 0px !important; background-repeat: initial initial !important; }
.CodeMirror-gutter-background { position: absolute; top: 0px; bottom: 0px; z-index: 4; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-top-left-radius: 0px; border-top-right-radius: 0px; border-bottom-right-radius: 0px; border-bottom-left-radius: 0px; border-width: 0px; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; word-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; background-position: 0px 0px; background-repeat: initial initial; }
.CodeMirror-wrap pre { word-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right-width: 30px; border-right-style: solid; border-right-color: transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right-style: none; width: auto; }
.CodeMirror-linebackground { position: absolute; left: 0px; right: 0px; top: 0px; bottom: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; border-right-style: none; width: 0px; visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.CodeMirror-selected { background-color: rgb(217, 217, 217); background-position: initial initial; background-repeat: initial initial; }
.CodeMirror-focused .CodeMirror-selected { background-color: rgb(215, 212, 240); background-position: initial initial; background-repeat: initial initial; }
.cm-searching { background-color: rgba(255, 255, 0, 0.4); background-position: initial initial; background-repeat: initial initial; }
@media print { 
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}
.CodeMirror-lint-markers { width: 16px; }
.CodeMirror-lint-tooltip { background-color: infobackground; border: 1px solid rgb(0, 0, 0); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; color: infotext; font-family: var(--monospace); overflow: hidden; padding: 2px 5px; position: fixed; white-space: pre-wrap; z-index: 10000; max-width: 600px; opacity: 0; transition: opacity 0.4s; font-size: 0.8em; }
.CodeMirror-lint-mark-error, .CodeMirror-lint-mark-warning { background-position: left bottom; background-repeat: repeat no-repeat; }
.CodeMirror-lint-mark-error { background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAQAAAADCAYAAAC09K7GAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9sJDw4cOCW1/KIAAAAZdEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIEdJTVBXgQ4XAAAAHElEQVQI12NggIL/DAz/GdA5/xkY/qPKMDAwAADLZwf5rvm+LQAAAABJRU5ErkJggg==); }
.CodeMirror-lint-marker-error, .CodeMirror-lint-marker-warning { cursor: pointer; display: inline-block; height: 16px; width: 16px; vertical-align: middle; position: relative; background-position: center center; background-repeat: no-repeat no-repeat; }
.CodeMirror-lint-message-error, .CodeMirror-lint-message-warning { padding-left: 18px; background-position: left top; background-repeat: no-repeat no-repeat; }
.CodeMirror-lint-marker-error, .CodeMirror-lint-message-error { background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAHlBMVEW7AAC7AACxAAC7AAC7AAAAAAC4AAC5AAD///+7AAAUdclpAAAABnRSTlMXnORSiwCK0ZKSAAAATUlEQVR42mWPOQ7AQAgDuQLx/z8csYRmPRIFIwRGnosRrpamvkKi0FTIiMASR3hhKW+hAN6/tIWhu9PDWiTGNEkTtIOucA5Oyr9ckPgAWm0GPBog6v4AAAAASUVORK5CYII=); }
.CodeMirror-lint-marker-warning, .CodeMirror-lint-message-warning { background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAANlBMVEX/uwDvrwD/uwD/uwD/uwD/uwD/uwD/uwD/uwD6twD/uwAAAADurwD2tQD7uAD+ugAAAAD/uwDhmeTRAAAADHRSTlMJ8mN1EYcbmiixgACm7WbuAAAAVklEQVR42n3PUQqAIBBFUU1LLc3u/jdbOJoW1P08DA9Gba8+YWJ6gNJoNYIBzAA2chBth5kLmG9YUoG0NHAUwFXwO9LuBQL1giCQb8gC9Oro2vp5rncCIY8L8uEx5ZkAAAAASUVORK5CYII=); }
.CodeMirror-lint-marker-multiple { background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAcAAAAHCAMAAADzjKfhAAAACVBMVEUAAAAAAAC/v7914kyHAAAAAXRSTlMAQObYZgAAACNJREFUeNo1ioEJAAAIwmz/H90iFFSGJgFMe3gaLZ0od+9/AQZ0ADosbYraAAAAAElFTkSuQmCC); width: 100%; height: 100%; background-position: right bottom; background-repeat: no-repeat no-repeat; }


:root {
    --side-bar-bg-color: #fafafa;
    --control-text-color: #777;
}

@include-when-export url(https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext);

@font-face {
    font-family: 'Open Sans';
    font-style: normal;
    font-weight: normal;
    src: local('Open Sans Regular'),url('file:///Users/spurs/Library/Application%20Support/abnerworks.Typora/themes/github/400.woff') format('woff')
}

@font-face {
    font-family: 'Open Sans';
    font-style: italic;
    font-weight: normal;
    src: local('Open Sans Italic'),url('file:///Users/spurs/Library/Application%20Support/abnerworks.Typora/themes/github/400i.woff') format('woff')
}

@font-face {
    font-family: 'Open Sans';
    font-style: normal;
    font-weight: bold;
    src: local('Open Sans Bold'),url('file:///Users/spurs/Library/Application%20Support/abnerworks.Typora/themes/github/700.woff') format('woff')
}

@font-face {
    font-family: 'Open Sans';
    font-style: italic;
    font-weight: bold;
    src: local('Open Sans Bold Italic'),url('file:///Users/spurs/Library/Application%20Support/abnerworks.Typora/themes/github/700i.woff') format('woff')
}

html {
    font-size: 16px;
}

body {
    font-family: "Open Sans","Clear Sans","Helvetica Neue",Helvetica,Arial,sans-serif;
    color: rgb(51, 51, 51);
    line-height: 1.6;
}

#write{
    max-width: 860px;
  	margin: 0 auto;
  	padding: 20px 30px 40px 30px;
	padding-top: 20px;
    padding-bottom: 100px;
}
#write > ul:first-child,
#write > ol:first-child{
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}
body > *:last-child {
    margin-bottom: 0 !important;
}
a {
    color: #4183C4;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}
h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    /*background: url("file:///Users/spurs/Library/Application%20Support/images/modules/styleguide/para.png") no-repeat 10px center;*/
    text-decoration: none;
}
h1 tt,
h1 code {
    font-size: inherit;
}
h2 tt,
h2 code {
    font-size: inherit;
}
h3 tt,
h3 code {
    font-size: inherit;
}
h4 tt,
h4 code {
    font-size: inherit;
}
h5 tt,
h5 code {
    font-size: inherit;
}
h6 tt,
h6 code {
    font-size: inherit;
}
h1 {
    padding-bottom: .3em;
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}
h2 {
   padding-bottom: .3em;
    font-size: 1.75em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}
h3 {
    font-size: 1.5em;
    line-height: 1.43;
}
h4 {
    font-size: 1.25em;
}
h5 {
    font-size: 1em;
}
h6 {
   font-size: 1em;
    color: #777;
}
p,
blockquote,
ul,
ol,
dl,
table{
    margin: 0.8em 0;
}
li>ol,
li>ul {
    margin: 0 0;
}
hr {
    height: 4px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
    border-bottom: 1px solid #ddd;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}
body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}
body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}
body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}
a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}
h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}
li p.first {
    display: inline-block;
}
ul,
ol {
    padding-left: 30px;
}
ul:first-child,
ol:first-child {
    margin-top: 0;
}
ul:last-child,
ol:last-child {
    margin-bottom: 0;
}
blockquote {
    border-left: 4px solid #dddddd;
    padding: 0 15px;
    color: #777777;
}
blockquote blockquote {
    padding-right: 0;
}
table {
    padding: 0;
    word-break: initial;
}
table tr {
    border-top: 1px solid #cccccc;
    margin: 0;
    padding: 0;
}
table tr:nth-child(2n) {
    background-color: #f8f8f8;
}
table tr th {
    font-weight: bold;
    border: 1px solid #cccccc;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}
table tr td {
    border: 1px solid #cccccc;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}
table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}
table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

.CodeMirror-gutters {
    border-right: 1px solid #ddd;
}

.md-fences,
code,
tt {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
    border-radius: 3px;
    padding: 0;
    font-family: Consolas, "Liberation Mono", Courier, monospace;
    padding: 2px 4px 0px 4px;
    font-size: 0.9em;
}

.md-fences {
    margin-bottom: 15px;
    margin-top: 15px;
    padding: 0.2em 1em;
    padding-top: 8px;
    padding-bottom: 6px;
}

.md-task-list-item > input {
  margin-left: -1.3em;
}

@media screen and (min-width: 914px) {
    /*body {
        width: 854px;
        margin: 0 auto;
    }*/
}
@media print {
    html {
        font-size: 13px;
    }
    table,
    pre {
        page-break-inside: avoid;
    }
    pre {
        word-wrap: break-word;
    }
}

.md-fences {
	background-color: #f8f8f8;
}
#write pre.md-meta-block {
	padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
	bottom: .375rem;
}

#write>h3.md-focus:before{
	left: -1.5625rem;
	top: .375rem;
}
#write>h4.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h5.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h6.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    font-family: Consolas, "Liberation Mono", Courier, monospace;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag{
	color: inherit;
}

.md-toc { 
    margin-top:20px;
    padding-bottom:20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header, .context-menu, .megamenu-content, footer{
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state{
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}


 .typora-export p {white-space: normal;} 
</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-mac'><div class='md-toc' mdtype='toc'><p class="md-toc-content"><span class="md-toc-item md-toc-h2" data-ref="n3"><a class="md-toc-inner" style="" href="#header-n3">03-26</a></span><span class="md-toc-item md-toc-h2" data-ref="n4"><a class="md-toc-inner" style="" href="#header-n4">03-27</a></span><span class="md-toc-item md-toc-h2" data-ref="n5"><a class="md-toc-inner" style="" href="#header-n5">03-28</a></span><span class="md-toc-item md-toc-h3" data-ref="n6"><a class="md-toc-inner" style="" href="#header-n6">1. 常见的损失函数</a></span><span class="md-toc-item md-toc-h3" data-ref="n27"><a class="md-toc-inner" style="" href="#header-n27">2. 简单介绍以下逻辑回归</a></span><span class="md-toc-item md-toc-h3" data-ref="n32"><a class="md-toc-inner" style="" href="#header-n32">3. hashmap和hashtable的区别</a></span><span class="md-toc-item md-toc-h3" data-ref="n49"><a class="md-toc-inner" style="" href="#header-n49">4. 分类问题中，经常遇到正负样本数据量不均衡的问题，有什么处理方法</a></span><span class="md-toc-item md-toc-h3" data-ref="n69"><a class="md-toc-inner" style="" href="#header-n69">5. 朴素贝叶斯分类的基本假设是每个变量相互独立</a></span><span class="md-toc-item md-toc-h3" data-ref="n70"><a class="md-toc-inner" style="" href="#header-n70">6. 关于SVM支持向量机</a></span><span class="md-toc-item md-toc-h3" data-ref="n81"><a class="md-toc-inner" style="" href="#header-n81">7.在HMM中</a></span><span class="md-toc-item md-toc-h3" data-ref="n95"><a class="md-toc-inner" style="" href="#header-n95">8.kmeans的复杂度？</a></span><span class="md-toc-item md-toc-h3" data-ref="n104"><a class="md-toc-inner" style="" href="#header-n104">9.研究网络的话，看到stride为1的时候，当kernel=3，padding=1或者kernel=5，padding=2，一看就是卷积前后尺寸不变。</a></span><span class="md-toc-item md-toc-h3" data-ref="n105"><a class="md-toc-inner" style="" href="#header-n105">10.聚类算法结果的影响因素有分类准则、特征选取、模型相似度测量</a></span><span class="md-toc-item md-toc-h3" data-ref="n106"><a class="md-toc-inner" style="" href="#header-n106">11.Ensemble是论文刷结果的终极核武器，深度学习中一般有以下几种方式</a></span><span class="md-toc-item md-toc-h3" data-ref="n120"><a class="md-toc-inner" style="" href="#header-n120">12.什么是RNN</a></span><span class="md-toc-item md-toc-h3" data-ref="n155"><a class="md-toc-inner" style="" href="#header-n155">13.循环神经网络（recurrent）和递归神经网络（recurcive）</a></span><span class="md-toc-item md-toc-h3" data-ref="n166"><a class="md-toc-inner" style="" href="#header-n166">14.RNN中为什么要采用tanh而不是Relu作为激活函数？</a></span><span class="md-toc-item md-toc-h3" data-ref="n175"><a class="md-toc-inner" style="" href="#header-n175">15.RNN中的梯度问题</a></span><span class="md-toc-item md-toc-h3" data-ref="n198"><a class="md-toc-inner" style="" href="#header-n198">16.LSTM和GRU是从RNN演变而来</a></span><span class="md-toc-item md-toc-h3" data-ref="n199"><a class="md-toc-inner" style="" href="#header-n199">17.standford的nlp课程</a></span><span class="md-toc-item md-toc-h3" data-ref="n200"><a class="md-toc-inner" style="" href="#header-n200">18.迁移学习与fine-tuning有什么区别？</a></span><span class="md-toc-item md-toc-h3" data-ref="n201"><a class="md-toc-inner" style="" href="#header-n201">19.好文章-用深度学习（CNN RNN Attention）解决大规模文本分类问题 - 综述和实践</a></span><span class="md-toc-item md-toc-h3" data-ref="n202"><a class="md-toc-inner" style="" href="#header-n202">20.[译] 理解 LSTM 网络</a></span><span class="md-toc-item md-toc-h3" data-ref="n203"><a class="md-toc-inner" style="" href="#header-n203">21.详解梯度下降等各类优化算法</a></span><span class="md-toc-item md-toc-h3" data-ref="n204"><a class="md-toc-inner" style="" href="#header-n204">22.Adaboost算法的原理与推导</a></span><span class="md-toc-item md-toc-h2" data-ref="n206"><a class="md-toc-inner" style="" href="#header-n206">03-29</a></span><span class="md-toc-item md-toc-h3" data-ref="n207"><a class="md-toc-inner" style="" href="#header-n207">1.什么样的资料集不适合深度学习？</a></span><span class="md-toc-item md-toc-h3" data-ref="n218"><a class="md-toc-inner" style="" href="#header-n218">2.当深度学习性能遇到瓶颈的时候，如何优化？</a></span><span class="md-toc-item md-toc-h3" data-ref="n226"><a class="md-toc-inner" style="" href="#header-n226">3.如何提高深度学习性能？</a></span><span class="md-toc-item md-toc-h3" data-ref="n231"><a class="md-toc-inner" style="" href="#header-n231">4.广义线性模型是怎样被应用于深度学习中？</a></span><span class="md-toc-item md-toc-h3" data-ref="n242"><a class="md-toc-inner" style="" href="#header-n242">5.机器学习面试中应该了解那些理论知识？</a></span><span class="md-toc-item md-toc-h3" data-ref="n273"><a class="md-toc-inner" style="" href="#header-n273">6.归一化和标准化的区别？</a></span><span class="md-toc-item md-toc-h3" data-ref="n292"><a class="md-toc-inner" style="" href="#header-n292">7.随机森林如何处理缺失值？</a></span><span class="md-toc-item md-toc-h3" data-ref="n300"><a class="md-toc-inner" style="" href="#header-n300">8.随机森林如何评估特征重要性？</a></span><span class="md-toc-item md-toc-h3" data-ref="n308"><a class="md-toc-inner" style="" href="#header-n308">9.解释对偶的概念</a></span><span class="md-toc-item md-toc-h3" data-ref="n312"><a class="md-toc-inner" style="" href="#header-n312">10.如何进行特征选择？</a></span><span class="md-toc-item md-toc-h3" data-ref="n329"><a class="md-toc-inner" style="" href="#header-n329">11.数据预处理</a></span><span class="md-toc-item md-toc-h3" data-ref="n343"><a class="md-toc-inner" style="" href="#header-n343">12.特征工程</a></span><span class="md-toc-item md-toc-h3" data-ref="n346"><a class="md-toc-inner" style="" href="#header-n346">13.对比Sigmoid、Tanh、Relu这三个函数</a></span><span class="md-toc-item md-toc-h3" data-ref="n385"><a class="md-toc-inner" style="" href="#header-n385">14.既然上述三种激活函数各有优缺点，有没有更好的函数？</a></span><span class="md-toc-item md-toc-h3" data-ref="n412"><a class="md-toc-inner" style="" href="#header-n412">15.为什么引入非线性激励函数？</a></span><span class="md-toc-item md-toc-h3" data-ref="n423"><a class="md-toc-inner" style="" href="#header-n423">16.为什么ReLU要好过sigmoid/tanh函数？</a></span><span class="md-toc-item md-toc-h3" data-ref="n437"><a class="md-toc-inner" style="" href="#header-n437">17.为什么LSTM模型中既存在sigmoid又存在tanh两种激活函数？</a></span><span class="md-toc-item md-toc-h3" data-ref="n445"><a class="md-toc-inner" style="" href="#header-n445">18.衡量分类器的好坏？</a></span><span class="md-toc-item md-toc-h2" data-ref="n465"><a class="md-toc-inner" style="" href="#header-n465">03-30</a></span><span class="md-toc-item md-toc-h2" data-ref="n466"><a class="md-toc-inner" style="" href="#header-n466">03-31</a></span><span class="md-toc-item md-toc-h2" data-ref="n467"><a class="md-toc-inner" style="" href="#header-n467">04-01</a></span><span class="md-toc-item md-toc-h2" data-ref="n468"><a class="md-toc-inner" style="" href="#header-n468">END</a></span></p></div><h2><a name='header-n3' class='md-header-anchor '></a>03-26</h2><h2><a name='header-n4' class='md-header-anchor '></a>03-27</h2><h2><a name='header-n5' class='md-header-anchor '></a>03-28</h2><h3><a name='header-n6' class='md-header-anchor '></a>1. 常见的损失函数</h3><ul><li>模型<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.413ex" height="2.577ex" viewBox="0 -806.1 1900 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use><use xlink:href="#E1-MJMAIN-28" x="550" y="0"></use><use xlink:href="#E1-MJMATHI-78" x="939" y="0"></use><use xlink:href="#E1-MJMAIN-29" x="1511" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1">f(x)</script>关于训练数据集的平均损失称为经验风险</li><li>经验风险最小化的策略认为，经验风险最小的模型是最优的模型，则按照经验风险最小化求得最优模型</li><li>当样本容量很小时候，经验风险最小化的策略容易产生过拟合的现象，结构风险最小化可以防止过拟合。</li><li>结构风险是在经验风险的基础上加上表示模型复杂度的正则化项。</li><li><strong>这样，监督学习问题就变成了经验风险或结构风险最优化的问题。</strong></li></ul><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/lost1.jpg' alt='' /></p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/lost2.jpg' alt='' /></p><h3><a name='header-n27' class='md-header-anchor '></a>2. 简单介绍以下逻辑回归</h3><ul><li>Logistic回归的目的是从特征学习出一个0/1分类模型，而这个模型是将特征的线性组合作为自变量，由于自变量的取值范围是负无穷到正无穷。因此，使用logistic函数将自变量映射到（0,1）上，映射后的值被认为是属于y=1的概率。</li></ul><h3><a name='header-n32' class='md-header-anchor '></a>3. hashmap和hashtable的区别</h3><ul><li>HashMap基于HashTable实现，不同之处在于HashMap是飞同步的，并且允许null，即null key和null value，HashTable则不允许null</li><li>凡是hashmap、hashset等带有hash字眼的都是基于hashtable实现的，</li><li>没带hash字眼的set、map等都是基于红黑树实现的，</li><li>前者无序，后者有序。</li><li><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/hash.jpg' alt='' /></li></ul><h3><a name='header-n49' class='md-header-anchor '></a>4. 分类问题中，经常遇到正负样本数据量不均衡的问题，有什么<a href='https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/'>处理方法</a></h3><blockquote><p>例如正样本10w条数据，负样本1w条数据。</p></blockquote><ul><li>将负样本重复10次，生成10w样本量，打乱顺序参与分类</li><li>直接进行分类，可以最大限度利用数据</li><li>从10w正样本中，随机抽取1w参与分类</li><li>将负样本每个权重设置为10，正样本权重为1，参与训练过程。</li></ul><blockquote><p>以上几种方法各有优缺点，需要具体问题具体分析。</p></blockquote><h3><a name='header-n69' class='md-header-anchor '></a>5. 朴素贝叶斯分类的基本假设是每个变量相互独立</h3><h3><a name='header-n70' class='md-header-anchor '></a>6. 关于SVM支持向量机</h3><ul><li>L2正则项，作用是最大化分类间隔，使得分类器拥有更强的泛化能力。</li><li>Hinge损失函数，作用是最小化经验分类错误</li><li>分类间隔是<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.308ex" height="2.577ex" viewBox="0 -806.1 2716 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E2-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E2-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path stroke-width="0" id="E2-MJMAIN-2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path><path stroke-width="0" id="E2-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E2-MJMAIN-32" x="0" y="0"></use><use xlink:href="#E2-MJMAIN-2F" x="500" y="0"></use><use xlink:href="#E2-MJMAIN-2225" x="1000" y="0"></use><use xlink:href="#E2-MJMATHI-77" x="1500" y="0"></use><use xlink:href="#E2-MJMAIN-2225" x="2216" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2">2/\|w\|</script>，其中<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.986ex" height="2.577ex" viewBox="0 -806.1 1716 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E3-MJMAIN-2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path><path stroke-width="0" id="E3-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E3-MJMAIN-2225" x="0" y="0"></use><use xlink:href="#E3-MJMATHI-77" x="500" y="0"></use><use xlink:href="#E3-MJMAIN-2225" x="1216" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-3">\|w\|</script>代表向量的模</li></ul><h3><a name='header-n81' class='md-header-anchor '></a>7.在HMM中</h3><ul><li>EM算法，只有观测序列，无状态序列是学习模型参数，即Baum-Welch算法</li><li>维特比算法，用动态规划解决HMM的预测问题</li><li>前向后向算法，用来算概率</li><li>极大似然估计，即观测序列和状态序列都存在时候的监督学习算法，用来估计参数</li></ul><h3><a name='header-n95' class='md-header-anchor '></a>8.kmeans的复杂度？</h3><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 4px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 30px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">选择K的点作为初试质心</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">repeat</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tab" role="presentation" cm-text="	">    </span><span class="cm-variable">将每个点指派到最近的质心，形成K的族</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">重新计算每个族的质心</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">until</span> <span class="cm-variable">族不发生变化或达到最大迭代次数</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: transparent; top: 118px;"></div><div class="CodeMirror-gutters" style="display: none; height: 148px;"></div></div></div></pre><ul><li>时间复杂度：<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.06ex" height="2.577ex" viewBox="0 -806.1 3901 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E4-MJMATHI-4F" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path><path stroke-width="0" id="E4-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E4-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E4-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path stroke-width="0" id="E4-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E4-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E4-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E4-MJMATHI-4F" x="0" y="0"></use><use xlink:href="#E4-MJMAIN-28" x="763" y="0"></use><use xlink:href="#E4-MJMATHI-74" x="1152" y="0"></use><use xlink:href="#E4-MJMATHI-6B" x="1513" y="0"></use><use xlink:href="#E4-MJMATHI-6D" x="2034" y="0"></use><use xlink:href="#E4-MJMATHI-6E" x="2912" y="0"></use><use xlink:href="#E4-MJMAIN-29" x="3512" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-4">O(tkmn)</script>，其中t为迭代次数，k为族的个数，m为记录数，n为维数</li><li>空间复杂度：<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.062ex" height="2.577ex" viewBox="0 -806.1 6484.9 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E5-MJMATHI-4F" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path><path stroke-width="0" id="E5-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E5-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E5-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E5-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path stroke-width="0" id="E5-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E5-MJMAIN-2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path stroke-width="0" id="E5-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E5-MJMATHI-4F" x="0" y="0"></use><use xlink:href="#E5-MJMAIN-28" x="763" y="0"></use><use xlink:href="#E5-MJMAIN-28" x="1152" y="0"></use><use xlink:href="#E5-MJMATHI-6D" x="1541" y="0"></use><use xlink:href="#E5-MJMAIN-2B" x="2641" y="0"></use><use xlink:href="#E5-MJMATHI-6B" x="3641" y="0"></use><use xlink:href="#E5-MJMAIN-29" x="4162" y="0"></use><use xlink:href="#E5-MJMAIN-2217" x="4773" y="0"></use><use xlink:href="#E5-MJMATHI-6E" x="5495" y="0"></use><use xlink:href="#E5-MJMAIN-29" x="6095" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-5">O((m + k) * n)</script>，其中k为族的个数，m为记录数，n为维数</li></ul><h3><a name='header-n104' class='md-header-anchor '></a>9.研究网络的话，看到stride为1的时候，当kernel=3，padding=1或者kernel=5，padding=2，一看就是卷积前后尺寸不变。</h3><h3><a name='header-n105' class='md-header-anchor '></a>10.聚类算法结果的影响因素有分类准则、特征选取、模型相似度测量</h3><h3><a name='header-n106' class='md-header-anchor '></a>11.Ensemble是论文刷结果的终极核武器，深度学习中一般有以下几种方式</h3><ul><li>同样的参数，不同的初始化方式</li><li>不同的参数，通过cross-validation，选取最好的几组</li><li>同样的参数，模型训练的不同阶段，即不同迭代次数的模型</li><li>不同的模型，进行线性融合，例如rnn和传统模型</li></ul><h3><a name='header-n120' class='md-header-anchor '></a>12.什么是RNN</h3><ul><li><p>RNNs的目的是处理序列数据。再传统的神经网络模型中，是从输入层到隐藏层再到输出层，层与层之间是全连接的，而每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能为力。例如，你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。RNNs之所以称为循环神经网络，即一个序列的当前的输出与前面的输出有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前的输出的计算中，即<strong>隐藏层之间的节点不再无连接而是有链接的，并且隐藏层的输入不仅包括输入层的输出还包括了上一时刻的隐藏层的输出</strong>。</p></li><li><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/rnn1.jpg' alt='' /></p></li><li><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/rnn2.jpg' alt='' /></p></li><li><p>你会发现，在图中：有一条单向流动的信息流是从输入单元到达隐藏单元的，与此同时另一条单向流动的信息流从隐藏单元到达输出单元。<strong>在某些情况下，RNNs会打破后者的限制，引导信息从输出单元返回隐藏单元，这些被称为“Back Projections”，并且隐藏层的输入还包括上一隐藏层的状态，即隐藏层内的节点可以自连也可以互连</strong>。 </p></li><li><p><a href='https://zhuanlan.zhihu.com/p/28054589'>完全图解RNN、RNN变体、Seq2Seq、Attention机制</a></p><blockquote><p>文中介绍了经典的RNN和RNN的一些变化，例如（1 VS N，N VS 1，N VS N，N VS M）等结构变化，</p><p>其中的N vs M，这种结构又叫做Encoder-Decoder模型，也可以称之为Seq2Seq模型。</p><p>可以用于机器翻译，文本摘要，阅读理解，语音识别等。</p><p>对于长距离的依赖造成了模型性能的瓶颈，由此引入了Attention机制</p></blockquote></li><li><p><a href='https://blog.csdn.net/heyongluoyao8/article/details/48636251'>循环神经网络(RNN, Recurrent Neural Networks)介绍</a></p></li><li><p><a href='http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/'>Understanding LSTM Networks</a></p></li><li><p><a href='http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/'>Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs</a></p></li></ul><h3><a name='header-n155' class='md-header-anchor '></a>13.循环神经网络（recurrent）和递归神经网络（recurcive）</h3><ul><li>RNN从时间和空间两个不同维度来看，主要有两种结构：Recurrent Neural Network(循环神经网络)和RecursiveNeural Network(递归神经网络)。主要对于前者进行学习。</li><li>循环神经网络是一个在时间上传递的神经网络，网络的深度就是时间的长度。该神经网络是专门用来处理时间序列问题的，能够提取时间序列的信息。如果是前向神经网络，每一层的神经元信号只能够向下一层传播，样本的处理在时刻上是独立的。对于循环神经网络而言，神经元在这个时刻的输出可以直接影响下一个时间点的输入，因此该神经网络能够处理时间序列方面的问题。</li><li>RNN的重要特性是可以处理不定长的输入，得到一定的输出。将输入的序列使用RNN映射为一个固定大小的向量，然后将这个向量输入softmax层，用于分类和其他任务。随着，信息关联度越来越长，RNN 将变得无法去学习这些信息之间的联系，从而完全失去作用，为了解决RNN遗忘性这个问题，所以提出了 LSTM 的结构。同时对softmax和LSTM这两个概念进行学习。</li></ul><h3><a name='header-n166' class='md-header-anchor '></a>14.RNN中为什么要采用tanh而不是Relu作为激活函数？</h3><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/rnn21.png' alt='' /></p><p>那为什么同样的方法在RNN中不奏效呢？其实这一点Hinton在它的IRNN论文里面（arxiv：[<a href='https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1504.00941'>1504.00941] A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</a>）是很明确的提到的：</p><p><img src='https://pic1.zhimg.com/80/v2-2d19e8c9b39f40044853ea65f6edfb31_hd.jpg' alt='' /></p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/rnn22.png' alt='' /></p><h3><a name='header-n175' class='md-header-anchor '></a>15.RNN中的<a href='https://blog.csdn.net/han_xiaoyang/article/details/51932536'>梯度问题</a></h3><ul><li><p>梯度爆炸，在实验过程中，一旦梯度值增加很大，就会很容易探测其引起的溢出，这就是梯度爆炸问题</p><blockquote><p>解决方法：</p><p>截断模型</p></blockquote></li><li><p>梯度弥散，当梯度值接近于零时，将会导致梯度的不断衰减，这就是梯度弥散的问题</p><blockquote><p>解决方法：</p><ol start='' ><li>将随机化W改为一个有关联的矩阵初始化</li><li>使用Relu代替sigmoid函数。</li></ol></blockquote></li></ul><h3><a name='header-n198' class='md-header-anchor '></a>16.LSTM和GRU是从RNN演变而来</h3><h3><a name='header-n199' class='md-header-anchor '></a>17.standford的<a href='http://web.stanford.edu/class/cs224n/archive/WWW_1617/index.html'>nlp课程</a></h3><h3><a name='header-n200' class='md-header-anchor '></a>18.<a href='https://www.zhihu.com/question/49534423'>迁移学习与fine-tuning有什么区别？</a></h3><h3><a name='header-n201' class='md-header-anchor '></a>19.好文章-<a href='https://zhuanlan.zhihu.com/p/25928551'>用深度学习（CNN RNN Attention）解决大规模文本分类问题 - 综述和实践</a></h3><h3><a name='header-n202' class='md-header-anchor '></a>20.<a href='https://www.jianshu.com/p/9dc9f41f0b29/'>[译] 理解 LSTM 网络</a></h3><h3><a name='header-n203' class='md-header-anchor '></a>21.<a href='https://ask.julyedu.com/question/7913'>详解梯度下降等各类优化算法</a></h3><h3><a name='header-n204' class='md-header-anchor '></a>22.<a href='http://blog.csdn.net/v_july_v/article/details/40718799'>Adaboost算法的原理与推导</a></h3><h2><a name='header-n206' class='md-header-anchor '></a>03-29</h2><h3><a name='header-n207' class='md-header-anchor '></a>1.什么样的资料集不适合深度学习？</h3><ul><li>数据集太小，数据样本不足时，深度学习相对于其他机器学习算法，没有明显优势</li><li>数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像、语音、自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理，</li><li>举个例子：预测一个人的健康状况，相关的特征会有年龄、职业、收入、家庭状况等因素，将这些因素打乱，并不会影响相关的结果。</li></ul><h3><a name='header-n218' class='md-header-anchor '></a>2.当深度学习性能遇到瓶颈的时候，如何优化？</h3><ul><li><a href='https://blog.csdn.net/han_xiaoyang/article/details/53453145'>机器学习性能改善备忘录</a></li><li>可以尝试基于数据、基于算法、用算法调参、借助模型融合等。</li></ul><h3><a name='header-n226' class='md-header-anchor '></a>3.如何提高深度学习性能？</h3><ul><li><a href='https://blog.csdn.net/han_xiaoyang/article/details/52654879'>如何提高深度学习性能</a></li></ul><h3><a name='header-n231' class='md-header-anchor '></a>4.广义线性模型是怎样被应用于深度学习中？</h3><ul><li>从统计学的角度看深度学习，可以看做是递归的广义线性模型</li><li>广义线性模型相对于经典的线性模型<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.079ex" height="2.461ex" viewBox="0 -755.9 4770 1059.4" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E6-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E6-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E6-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="0" id="E6-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E6-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E6-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E6-MJMATHI-79" x="0" y="0"></use><use xlink:href="#E6-MJMAIN-3D" x="774" y="0"></use><use xlink:href="#E6-MJMATHI-77" x="1830" y="0"></use><use xlink:href="#E6-MJMATHI-78" x="2546" y="0"></use><use xlink:href="#E6-MJMAIN-2B" x="3340" y="0"></use><use xlink:href="#E6-MJMATHI-62" x="4341" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-6">y=wx+b</script>，核心在于引入了<strong>连接函数</strong>，<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.955ex" height="2.577ex" viewBox="0 -806.1 1702.7 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E7-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path stroke-width="0" id="E7-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E7-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="0" id="E7-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E7-MJMATHI-67" x="0" y="0"></use><use xlink:href="#E7-MJMAIN-28" x="480" y="0"></use><use xlink:href="#E7-MJMAIN-2E" x="869" y="0"></use><use xlink:href="#E7-MJMAIN-29" x="1313" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-7">g(.)</script>，形式变为了<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.334ex" height="2.811ex" viewBox="0 -906.7 7032.6 1210.2" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E8-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E8-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E8-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path stroke-width="0" id="E8-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E8-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E8-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E8-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="0" id="E8-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E8-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E8-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path stroke-width="0" id="E8-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E8-MJMATHI-79" x="0" y="0"></use><use xlink:href="#E8-MJMAIN-3D" x="774" y="0"></use><g transform="translate(1830,0)"><use xlink:href="#E8-MJMATHI-67" x="0" y="0"></use><g transform="translate(480,362)"><use transform="scale(0.707)" xlink:href="#E8-MJMAIN-2212" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E8-MJMAIN-31" x="778" y="0"></use></g></g><use xlink:href="#E8-MJMAIN-28" x="3315" y="0"></use><use xlink:href="#E8-MJMATHI-77" x="3704" y="0"></use><use xlink:href="#E8-MJMATHI-78" x="4420" y="0"></use><use xlink:href="#E8-MJMAIN-2B" x="5214" y="0"></use><use xlink:href="#E8-MJMATHI-62" x="6214" y="0"></use><use xlink:href="#E8-MJMAIN-29" x="6643" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-8">y=g^{-1}(wx+b)</script>.</li><li>深度学习时递归的广义线性模型，神经元的激活函数，就是广义线性模型的连接函数。逻辑回归的Logistic函数即为神经元激活函数中的sigmoid函数，很多类似的方法再统计学和神经网络中有不同的名称，</li></ul><h3><a name='header-n242' class='md-header-anchor '></a>5.机器学习面试中应该了解那些理论知识？</h3><blockquote><p>来源<a href='https://www.zhihu.com/question/62482926' target='_blank' >https://www.zhihu.com/question/62482926</a></p></blockquote><ol start='' ><li><p>理论功底，主要考察对机器学习模型的理解，选择性提问(如果遇到面试者的研究方向自己不了解但感兴趣，会很欣喜，可以趁机学习一下)这块儿的问题会比价零碎，都是我自己深入思考过的<strong>(背书是没有用的，这里任何一个点都可以给你展开问下去)</strong></p><ul><li>过拟合欠拟合（举几个例子让你判断下，顺便问问交叉验证的目的，超参数搜索方法，earlystopping）、L1和L2正则的做法、正则化背后的思想（顺便问问BatchNorm、Covariance Shift）、L1正则产生稀疏解的原理、逻辑回归为何线性模型（顺便问问LR如何解决低维不可分、从图模型的角度看LR和朴素贝叶斯和无监督）、几种参数估计方法、MLE/MAP/贝叶斯的联系和区别，简单说下SVM的支持向量（顺便问问KKT条件、为何对偶、核的通俗理解）、GBDT随机森林是否并行（顺便问问bagging boosting）、生成模型判别模型举个例子、聚类方法的掌握（顺便问问Kmeans的EM推导思路、谱聚类和Graph-cut的理解）、梯度下降方法和牛顿类方法的区别（顺便问问Adam、L-BFGS的思路）、本监督的思想（顺便问问一些特定半监督算法是如何利用无标签数据的、从MAP角度看半监督）、常见的分类模型的评价指标（顺便问问交叉熵、ROC如何绘制、AUC的物理含义、类别不均衡样本）</li><li>CNN中的卷积操作和卷积核的作用，maxpooling的作用、卷积层和全连接层的联系、梯度爆炸和消失的概念（顺便问问神经网络权重初始化的方法、为何能缓解梯度爆炸消失、CNN中有那些解决办法、LSTM如何解决的、如何梯度修剪、dropout如何再用在RNN系列网络中、dropout防止过拟合）、为何卷积可以用在图像、语音、语句上(顺便问问channel再不同类型数据源中的含义)</li><li>如果面试者跟我一样做NLP、推荐系统，我会继续追问CRF和逻辑回归、最大熵模型的关系、CRF的优化方法、CRF和MRF的联系、HMM和CRF的关系（顺便问问朴素贝叶斯和HMM的联系，LSTM+CRF用于序列标注的原理、CRF的点函数和边函数、CRF的经验分布），wordembedding的几种常用方法和原理（顺便问问language model、perplexity评价指标、word2vec和glove的异同、topic model说一说、为何CNN能用在文本分类、syntactic和semantic问题举例、常见的sentence embedding方法、注意力机制（顺便问问注意力机制的几种不同情形，为何引入、seq2seq原理）、序列标注的评价指标、语义消岐的做法、常见的跟word有关的特征、factorization machine、常见的矩阵分解模型、如何把分类模型用于商品推荐（包括数据集划分、模型验证等）、序列学习、wide&amp;deep model（顺便问问为何wide和deep）</li></ul></li><li><p>代码能力，主要考察事项算法和优化代码的能力，一般会先看面试者的github repo（如果简历给出来了），看代码风格、架构能力（遇到大神会认真学习一个），如果没有github，我会避免问典型的应试题，而是问一些我本人从实际问题中抽象处理的小算法题。</p><ul><li>给出节点的矩阵和边的矩阵，求路径和最大路径（来源于viterbi算法，本质就是个动态规划），至少给出思路和伪代码（顺便聊聊前向传播和后向传播）</li><li>给出一个数组，数组元素是pair对儿，表示一个有向无环图&lt;父节点，子节点&gt;，用最优的方法，将其变成一个新的有序数组，数组元素是该有向无环图所有节点，数组的有序性体现在：父亲节点再孩子节点前面</li></ul></li><li><p>项目能力，主要考察解决问题的思路、填坑能力。这部分最考验面试官功底，要能从面试者浮夸的描述中寻找有意义的点，并一步步深挖。另外很多dirty work(数据预处理、文本清洗、调参经验、算法复杂度优化、Bad case分析、修改损失函数等)也是在这步深挖</p></li></ol><h3><a name='header-n273' class='md-header-anchor '></a>6.归一化和标准化的区别？</h3><ul><li><p>归一化：</p><ul><li>把数变为(0,1)之间的小数，主要是为了数据处理方便提出来的，把数据映射到0-1范围之内处理，更方便快捷</li><li>把有量纲的表达式变为无量纲表达式，归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。</li></ul></li><li><p>标准化</p><ul><li>把数据按比例缩放，使之落在一个小的指定区间。由于信用指标体系的各个指标度量单位是不同的，为了能够将指标参与评价计算，需要对指标进行规范化处理，通过函数变换将其数值映射到某个数值区间。</li></ul></li></ul><h3><a name='header-n292' class='md-header-anchor '></a>7.随机森林如何处理缺失值？</h3><ul><li>类别型变量用众数，连续型变量用中位数填补</li><li>用na.roughfix补上缺失值</li></ul><h3><a name='header-n300' class='md-header-anchor '></a>8.随机森林如何评估特征重要性？</h3><ul><li>decrease GINI</li><li>decrease accuracy</li></ul><h3><a name='header-n308' class='md-header-anchor '></a>9.解释对偶的概念</h3><blockquote><p>一个优化问题可以从两个角度进行考察，一个是primal问题，一个是dual问题，一般情况下，对偶问题给出主问题最优值的下界，再强对偶性成立的情况下，由对偶问题可以得到主问题的最优下界，对偶问题是凸优化问题，可以进行较好的求解，SVM中就是将primal问题转换为dual问题进行求解，从而进一步引入核函数的思想。</p></blockquote><h3><a name='header-n312' class='md-header-anchor '></a>10.如何进行特征选择？</h3><blockquote><p>特征选择是一个重要的数据预处理过程，主要有两个原因：一是减少特征数量、降维，使得模型泛化能力更强，减少过拟合，二是增强对特征和特征值之间的理解。</p></blockquote><ul><li>去除方差小的特征</li><li>正则化。L1正则化生成稀疏的模型。L2正则化的表现更加稳定，由于有用的特征往往对应系数非零。</li><li>随机森林。对于分类问题，通常采用基尼不纯度或者信息增益，对于回归问题，通常采用的是方差或者最小二乘法拟合。</li><li>稳定性选择。</li></ul><h3><a name='header-n329' class='md-header-anchor '></a>11.数据预处理</h3><ol start='' ><li>缺失值</li><li>连续值离散化</li><li>对定量特征二值化</li><li>皮尔逊相关系数去除高度相关的列</li></ol><h3><a name='header-n343' class='md-header-anchor '></a>12.特征工程</h3><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/feature.jpg' alt='' /></p><h3><a name='header-n346' class='md-header-anchor '></a>13.对比Sigmoid、Tanh、Relu这三个函数</h3><blockquote><p><a href='https://mp.weixin.qq.com/s/7DgiXCNBS5vb07WIKTFYRQ'>从ReLU到Sinc，26种神经网络激活函数可视化</a></p><p><a href='https://dashee87.github.io/data%20science/deep%20learning/visualising-activation-functions-in-neural-networks/'>原文出处</a></p><p>Visualising Activation Functions in Neural Networks</p></blockquote><ul><li><p>sigmoid函数又称为logistic函数，应用于logistic回归中。logistic回归的目的是从特征学习出一个0/1分类模型，而这个模型是将特性的线性组合作为自变量，由于自变量的取值范围是从负无穷到正无穷。因此，使用logistic函数是将自变量映射到(0，1)上，映射后的值被认为是属于y=1的概率。</p></li><li><p>sigmoid函数有如下几个缺点：</p><ul><li>正向计算包含指数，反向传播的导数也包含指数计算和除数计算，因而计算复杂度很高。</li><li>输出的均值非零，这样使得网络很容易发生梯度消失和梯度爆炸，这是batch normalization要解决的问题。</li></ul></li><li><p>对于ReLU来说，相对于sigmoid和tanh来说，有如下优点：</p><ul><li>收敛速度快，在实践中可以得知，他的收敛速度是sigmoid的6倍</li><li>ReLU会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合的问题</li></ul></li><li><p>ReLU的缺点是</p><ul><li>如果一个特别大的导数经过神经单元使得输入变得小于0，这样会使得这个单元永远得不到参数更新，因为输入小于0时，导数也是0。这样就形成了很多的dead cell。</li></ul></li></ul><h3><a name='header-n385' class='md-header-anchor '></a>14.既然上述三种激活函数各有优缺点，有没有更好的函数？</h3><ul><li><p>Leaky ReLU</p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/Leaky-ReLU.png' alt='' /></p></li><li><p>ELU</p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/ELU.png' alt='' /></p></li><li><p>sigmoid</p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/sigmoid1.png' alt='' /></p></li><li><p>tanh</p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/tanh.png' alt='' /></p></li><li><p>ReLU</p><p><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/ReLU.png' alt='' /></p></li></ul><h3><a name='header-n412' class='md-header-anchor '></a>15.为什么引入非线性激励函数？</h3><ol start='' ><li>对于神经网络而言，网络的每一层相当于<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.801ex" height="2.928ex" viewBox="0 -956.9 8525.2 1260.5" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E9-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E9-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E9-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="0" id="E9-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E9-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E9-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path stroke-width="0" id="E9-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E9-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E9-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E9-MJMATHI-66" x="0" y="0"></use><use xlink:href="#E9-MJMAIN-28" x="550" y="0"></use><use xlink:href="#E9-MJMATHI-77" x="939" y="0"></use><use xlink:href="#E9-MJMATHI-78" x="1655" y="0"></use><use xlink:href="#E9-MJMAIN-2B" x="2449" y="0"></use><use xlink:href="#E9-MJMATHI-62" x="3449" y="0"></use><use xlink:href="#E9-MJMAIN-29" x="3878" y="0"></use><use xlink:href="#E9-MJMAIN-3D" x="4545" y="0"></use><use xlink:href="#E9-MJMATHI-66" x="5600" y="0"></use><use xlink:href="#E9-MJMAIN-28" x="6150" y="0"></use><g transform="translate(6539,0)"><use xlink:href="#E9-MJMATHI-77" x="0" y="0"></use><g transform="translate(716,362)"><use transform="scale(0.5)" xlink:href="#E9-MJMAIN-2032" x="0" y="513"></use></g></g><use xlink:href="#E9-MJMATHI-78" x="7564" y="0"></use><use xlink:href="#E9-MJMAIN-29" x="8136" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-9">f(wx+b)=f(w^{'}x)</script>，对于线性函数，其实相当于<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.839ex" height="2.577ex" viewBox="0 -806.1 3805.6 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E10-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E10-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E10-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E10-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E10-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E10-MJMATHI-66" x="0" y="0"></use><use xlink:href="#E10-MJMAIN-28" x="550" y="0"></use><use xlink:href="#E10-MJMATHI-78" x="939" y="0"></use><use xlink:href="#E10-MJMAIN-29" x="1511" y="0"></use><use xlink:href="#E10-MJMAIN-3D" x="2177" y="0"></use><use xlink:href="#E10-MJMATHI-78" x="3233" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-10">f(x)=x</script>，那么在线性激活函数下，每一层相当于用一个矩阵去乘x，那么多层就是反复的用矩阵去乘以输入。根据矩阵的乘法法则，多个矩阵相乘得到一个大矩阵。所以在线性激励下，多层网络与一层网络相当。</li><li>非线性变换是深度学习有效的原因之一。原因在于非线性相当于对空间进行变换，变换完成后相当于对问题空间进行简化，原来线性不可解的问题现在变得可解了。</li><li>可以逼近任意函数</li></ol><h3><a name='header-n423' class='md-header-anchor '></a>16.为什么ReLU要好过sigmoid/tanh函数？</h3><ol start='' ><li>sigmoid函数，用到指数运算，计算量大。方向传播时候求误差梯度时，求导涉及除法和指数运算，计算量相对大</li><li>对于深层网络，sigmoid函数反向传播时候，很容易造成梯度消失的情况。在sigmoid函数接近饱和区时候，变换太缓慢了，导数趋于0，从而无法完成深层网络的训练</li><li>ReLU会使一步跟神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生</li></ol><blockquote><p>现在主流的做法是，在每一层的输入都做一步batch normalization，尽可能使得每一层网络的输入具有相同的分布。</p></blockquote><h3><a name='header-n437' class='md-header-anchor '></a>17.为什么LSTM模型中既存在sigmoid又存在tanh两种激活函数？</h3><ul><li>sigmoid用在各种gate上，产生0-1之间的数字，这个一般只有sigmoid最直接了</li><li>tanh用在了状态和输出上，是对数据的处理，这个用其他激活函数也是可以的</li></ul><h3><a name='header-n445' class='md-header-anchor '></a>18.衡量分类器的好坏？</h3><blockquote><p>这里首先知道TP、FN、FP、TN四种</p></blockquote><ul><li>精度precision=TP/(TP+FP)   == 认为正确的里面真正正确的</li><li>召回率recall=TP/(TP+FN)   == 全部正确的里面确实被认为是正确的</li><li>F1值： 2/F1 = 1/recall + 1/precision</li><li>ROC曲线：ROC空间是一个以伪阳率（FPR，false positive rate）为X轴，真阳率（TPR，true positive rate）为Y轴的二维坐标系所代表的平面。其中真阳率TPR = TP/P = recall， 伪阳率FPR=FP/N</li><li><img src='https://github.com/spurscoder/spurscoder.github.io/raw/master/img/home/recall-precision.png' alt='' /></li></ul><h2><a name='header-n465' class='md-header-anchor '></a>03-30</h2><h2><a name='header-n466' class='md-header-anchor '></a>03-31</h2><h2><a name='header-n467' class='md-header-anchor '></a>04-01</h2><h2><a name='header-n468' class='md-header-anchor '></a>END</h2><p>&nbsp;</p></div>
</body>
</html>